{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447b882b-5aff-47ac-a1da-6b7a0f76e04b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T10:07:29.062203Z",
     "iopub.status.busy": "2022-12-06T10:07:29.061794Z",
     "iopub.status.idle": "2022-12-06T10:07:29.074538Z",
     "shell.execute_reply": "2022-12-06T10:07:29.073293Z",
     "shell.execute_reply.started": "2022-12-06T10:07:29.062128Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test 1\n",
    "image_size = 128\n",
    "frames = 10\n",
    "max_images = 120000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c4d364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.0-cp310-cp310-manylinux1_x86_64.whl (24.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3.10/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3.10/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: appdirs in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (1.4.4)\n",
      "Requirement already satisfied: jaraco.text in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (3.11.0)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (9.0.0)\n",
      "Requirement already satisfied: ordered-set in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (4.1.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (21.3)\n",
      "Requirement already satisfied: pyparsing in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (3.0.9)\n",
      "Requirement already satisfied: tomli in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (2.0.1)\n",
      "Requirement already satisfied: validate-pyproject in /usr/lib/python3.10/site-packages (from setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (0.10.1)\n",
      "Requirement already satisfied: inflect in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (6.0.2)\n",
      "Requirement already satisfied: autocommand in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (2.2.2)\n",
      "Requirement already satisfied: jaraco.functools in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (3.5.2)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in /usr/lib/python3.10/site-packages (from jaraco.text->setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (4.2.0)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/lib/python3.10/site-packages (from inflect->jaraco.text->setuptools->nvidia-cublas-cu11==11.10.3.66->torch) (1.10.2)\n",
      "Installing collected packages: nvidia-cuda-nvrtc-cu11, numpy, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchvision\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.10 are installed in '/home/vallasc/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/vallasc/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0 torchvision-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "882c2eb2-e24e-41d7-9087-2f34941e54b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T10:09:10.454382Z",
     "iopub.status.busy": "2022-12-06T10:09:10.454115Z",
     "iopub.status.idle": "2022-12-06T10:09:11.702806Z",
     "shell.execute_reply": "2022-12-06T10:09:11.701797Z",
     "shell.execute_reply.started": "2022-12-06T10:09:10.454355Z"
    }
   },
   "outputs": [],
   "source": [
    "# GIF pre-processing\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "from math import floor, fabs\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "\n",
    "CHANNELS_TO_MODE = {\n",
    "    1 : 'L',\n",
    "    3 : 'RGB',\n",
    "    4 : 'RGBA'\n",
    "}\n",
    "\n",
    "def center_crop(img, new_width, new_height): \n",
    "    width = img.size[0]\n",
    "    height = img.size[1]\n",
    "    left = int(np.ceil((width - new_width) / 2))\n",
    "    right = width - int(np.floor((width - new_width) / 2))\n",
    "    top = int(np.ceil((height - new_height) / 2))\n",
    "    bottom = height - int(np.floor((height - new_height) / 2))\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "def resize_crop_img(img, width, height):\n",
    "    # width < height\n",
    "    if( img.size[0] < img.size[1]):\n",
    "      wpercent = (width/float(img.size[0]))\n",
    "      hsize = int((float(img.size[1])*float(wpercent)))\n",
    "      img = img.resize((width, hsize), Image.Resampling.LANCZOS)\n",
    "    else: # width >= height\n",
    "      hpercent = (height/float(img.size[1]))\n",
    "      wsize = int((float(img.size[0])*float(hpercent)))\n",
    "      img = img.resize((wsize, height), Image.Resampling.LANCZOS)\n",
    "    img = center_crop(img, width, height)\n",
    "    # print(img.size[0])\n",
    "    # print(img.size[1])\n",
    "    return img\n",
    "\n",
    "def transform_gif(img, new_width, new_height, frames, channels = 3):\n",
    "    assert channels in CHANNELS_TO_MODE, f'channels {channels} invalid'\n",
    "    mode = CHANNELS_TO_MODE[channels]\n",
    "    gif_frames = img.n_frames\n",
    "    for i in range(0, frames):\n",
    "        img.seek(i % gif_frames)\n",
    "        img_out = resize_crop_img(img, new_width, new_height)\n",
    "        yield img_out.convert(mode)\n",
    "        \n",
    "# tensor of shape (channels, frames, height, width) -> gif\n",
    "def video_tensor_to_gif(tensor, path, fps = 10, loop = 0, optimize = True):\n",
    "    print(\"Converting video tensors to GIF\")\n",
    "    images = map(T.ToPILImage(), tensor.unbind(dim = 1))\n",
    "    first_img, *rest_imgs = images\n",
    "    print(1000/fps)\n",
    "    first_img.save(path, save_all = True, append_images = rest_imgs, duration = int(1000/fps), loop = loop, optimize = optimize)\n",
    "    print(\"Gif saved\")\n",
    "    return images\n",
    "\n",
    "# gif -> (channels, frame, height, width) tensor\n",
    "def gif_to_tensor(path, width = 256, height = 256, frames = 32, channels = 3, transform = T.ToTensor()):\n",
    "    print(\"Converting GIF to video tensors\")\n",
    "    img = Image.open(path)\n",
    "    imgs = transform_gif(img, new_width = width, new_height = height, frames = frames, channels = channels)\n",
    "    tensors = tuple(map(transform, imgs))\n",
    "    return torch.stack(tensors, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fda94dd-6120-4ddc-8632-1cff5eb27e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T10:09:11.704252Z",
     "iopub.status.busy": "2022-12-06T10:09:11.703922Z",
     "iopub.status.idle": "2022-12-06T10:09:11.727879Z",
     "shell.execute_reply": "2022-12-06T10:09:11.726932Z",
     "shell.execute_reply.started": "2022-12-06T10:09:11.704228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-06 22:06:32--  https://raw.githubusercontent.com/raingo/TGIF-Release/master/data/tgif-v1.0.tsv\n",
      "Caricato certificato CA \"/etc/ssl/certs/ca-certificates.crt\"\n",
      "\n",
      "Risoluzione di raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8002::154, 2606:50c0:8001::154, ...\n",
      "Connessione a raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connesso.\n",
      "Richiesta HTTP inviata, in attesa di risposta... 200 OK\n",
      "Lunghezza: 18660908 (18M) [text/plain]\n",
      "Salvataggio in: «./train_data.tvs»\n",
      "\n",
      "./train_data.tvs    100%[===================>]  17,80M  4,93MB/s    in 3,7s    \n",
      "\n",
      "2022-12-06 22:06:36 (4,85 MB/s) - «./train_data.tvs» salvato [18660908/18660908]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "train_data = \"./train_data.tvs\"\n",
    "train_index = \"./train_index.txt\"\n",
    "\n",
    "if not os.path.exists(train_data):\n",
    "  !wget -O {train_data} https://raw.githubusercontent.com/raingo/TGIF-Release/master/data/tgif-v1.0.tsv\n",
    "\n",
    "current_index = 0\n",
    "texts = []\n",
    "list_videos = []\n",
    "\n",
    "def get_videos(index_start, index_end):\n",
    "    global texts\n",
    "    global list_videos\n",
    "    \n",
    "    texts = []\n",
    "    list_videos = []\n",
    "\n",
    "    with open(\"train_data.tvs\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            if i >= index_start and i< index_end :\n",
    "                file_img, file_text = line.split(\"\\t\")\n",
    "                try:\n",
    "                    print(f\"Downloading image {i}\");\n",
    "                    !wget -O download.gif -o /dev/null {file_img}\n",
    "                    tensor = gif_to_tensor('download.gif', width = image_size, height = image_size, frames = frames)\n",
    "                    list_videos.append(tensor)\n",
    "                    file_text = file_text[:-1] # Remove \\n\n",
    "                    texts.append(file_text)\n",
    "                    os.remove('download.gif')\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    pass\n",
    "            elif i > index_end:\n",
    "                break\n",
    "\n",
    "def get_next_videos():\n",
    "    global current_index\n",
    "    index = 0\n",
    "    if not os.path.exists(train_index):\n",
    "        with open(train_index, 'w') as fp:\n",
    "            fp.write(\"0\")\n",
    "    else:\n",
    "        with open(train_index, 'r') as fp:\n",
    "            index = int(fp.readlines()[0])\n",
    "    index_end = index + batch_size\n",
    "    get_videos(index, index_end)\n",
    "    with open(train_index, 'w') as fp:\n",
    "        fp.write(f\"{index_end}\")\n",
    "    current_index = index_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6060a45-ba90-4438-b5c3-d657cbe98d35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T10:09:11.730307Z",
     "iopub.status.busy": "2022-12-06T10:09:11.730035Z",
     "iopub.status.idle": "2022-12-06T10:09:45.131334Z",
     "shell.execute_reply": "2022-12-06T10:09:45.130063Z",
     "shell.execute_reply.started": "2022-12-06T10:09:11.730283Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image 0\n",
      "Converting GIF to video tensors\n",
      "Downloading image 1\n",
      "Converting GIF to video tensors\n",
      "Downloading image 2\n",
      "Converting GIF to video tensors\n",
      "Downloading image 3\n",
      "Converting GIF to video tensors\n",
      "Downloading image 4\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5\n",
      "Converting GIF to video tensors\n",
      "Downloading image 6\n",
      "Converting GIF to video tensors\n",
      "Downloading image 7\n",
      "Converting GIF to video tensors\n",
      "Downloading image 8\n",
      "Converting GIF to video tensors\n",
      "Downloading image 9\n",
      "Converting GIF to video tensors\n",
      "Downloading image 10\n",
      "Converting GIF to video tensors\n",
      "Downloading image 11\n",
      "Converting GIF to video tensors\n",
      "Downloading image 12\n",
      "Converting GIF to video tensors\n",
      "Downloading image 13\n",
      "Converting GIF to video tensors\n",
      "Downloading image 14\n",
      "Converting GIF to video tensors\n",
      "Downloading image 15\n",
      "Converting GIF to video tensors\n",
      "Downloading image 16\n",
      "Converting GIF to video tensors\n",
      "Downloading image 17\n",
      "Converting GIF to video tensors\n",
      "Downloading image 18\n",
      "Converting GIF to video tensors\n",
      "Downloading image 19\n",
      "Converting GIF to video tensors\n",
      "Downloading image 20\n",
      "Converting GIF to video tensors\n",
      "Downloading image 21\n",
      "Converting GIF to video tensors\n",
      "Downloading image 22\n",
      "Converting GIF to video tensors\n",
      "Downloading image 23\n",
      "Converting GIF to video tensors\n",
      "Downloading image 24\n",
      "Converting GIF to video tensors\n",
      "Downloading image 25\n",
      "Converting GIF to video tensors\n",
      "Downloading image 26\n",
      "Converting GIF to video tensors\n",
      "Downloading image 27\n",
      "Converting GIF to video tensors\n",
      "Downloading image 28\n",
      "Converting GIF to video tensors\n",
      "Downloading image 29\n",
      "Converting GIF to video tensors\n",
      "Downloading image 30\n",
      "Converting GIF to video tensors\n",
      "Downloading image 31\n",
      "Converting GIF to video tensors\n",
      "Downloading image 32\n",
      "Converting GIF to video tensors\n",
      "Downloading image 33\n",
      "Converting GIF to video tensors\n",
      "Downloading image 34\n",
      "Converting GIF to video tensors\n",
      "Downloading image 35\n",
      "Converting GIF to video tensors\n",
      "Downloading image 36\n",
      "Converting GIF to video tensors\n",
      "Downloading image 37\n",
      "Converting GIF to video tensors\n",
      "Downloading image 38\n",
      "Converting GIF to video tensors\n",
      "Downloading image 39\n",
      "^C\n",
      "Converting GIF to video tensors\n",
      "cannot identify image file 'download.gif'\n",
      "Downloading image 40\n",
      "Converting GIF to video tensors\n",
      "Downloading image 41\n",
      "Converting GIF to video tensors\n",
      "Downloading image 42\n",
      "Converting GIF to video tensors\n",
      "Downloading image 43\n",
      "Converting GIF to video tensors\n",
      "Downloading image 44\n",
      "Converting GIF to video tensors\n",
      "Downloading image 45\n",
      "Converting GIF to video tensors\n",
      "Downloading image 46\n",
      "Converting GIF to video tensors\n",
      "Downloading image 47\n",
      "Converting GIF to video tensors\n",
      "Downloading image 48\n",
      "Converting GIF to video tensors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mwhile\u001b[39;00m i \u001b[39m*\u001b[39m batch_size \u001b[39m<\u001b[39m max_images:\n\u001b[0;32m----> 4\u001b[0m     get_next_videos()\n\u001b[1;32m      5\u001b[0m     videos \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(list_videos, dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[1;32m      6\u001b[0m     torch\u001b[39m.\u001b[39msave(videos, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./TGIF/videos_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m, in \u001b[0;36mget_next_videos\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         index \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(fp\u001b[39m.\u001b[39mreadlines()[\u001b[39m0\u001b[39m])\n\u001b[1;32m     47\u001b[0m index_end \u001b[39m=\u001b[39m index \u001b[39m+\u001b[39m batch_size\n\u001b[0;32m---> 48\u001b[0m get_videos(index, index_end)\n\u001b[1;32m     49\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(train_index, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fp:\n\u001b[1;32m     50\u001b[0m     fp\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mindex_end\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mget_videos\u001b[0;34m(index_start, index_end)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDownloading image \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m);\n\u001b[1;32m     26\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mwget -O download.gif -o /dev/null \u001b[39m\u001b[39m{file_img}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m tensor \u001b[39m=\u001b[39m gif_to_tensor(\u001b[39m'\u001b[39;49m\u001b[39mdownload.gif\u001b[39;49m\u001b[39m'\u001b[39;49m, width \u001b[39m=\u001b[39;49m image_size, height \u001b[39m=\u001b[39;49m image_size, frames \u001b[39m=\u001b[39;49m frames)\n\u001b[1;32m     28\u001b[0m list_videos\u001b[39m.\u001b[39mappend(tensor)\n\u001b[1;32m     29\u001b[0m file_text \u001b[39m=\u001b[39m file_text[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m# Remove \\n\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 63\u001b[0m, in \u001b[0;36mgif_to_tensor\u001b[0;34m(path, width, height, frames, channels, transform)\u001b[0m\n\u001b[1;32m     61\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mopen(path)\n\u001b[1;32m     62\u001b[0m imgs \u001b[39m=\u001b[39m transform_gif(img, new_width \u001b[39m=\u001b[39m width, new_height \u001b[39m=\u001b[39m height, frames \u001b[39m=\u001b[39m frames, channels \u001b[39m=\u001b[39m channels)\n\u001b[0;32m---> 63\u001b[0m tensors \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39;49m(\u001b[39mmap\u001b[39;49m(transform, imgs))\n\u001b[1;32m     64\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(tensors, dim \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/transforms.py:135\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[1;32m    128\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchvision/transforms/functional.py:171\u001b[0m, in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    169\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(img, torch\u001b[39m.\u001b[39mByteTensor):\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mreturn\u001b[39;00m img\u001b[39m.\u001b[39;49mto(dtype\u001b[39m=\u001b[39;49mdefault_float_dtype)\u001b[39m.\u001b[39;49mdiv(\u001b[39m255\u001b[39;49m)\n\u001b[1;32m    172\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!mkdir TGIF\n",
    "i = 0\n",
    "while i * batch_size < max_images:\n",
    "    get_next_videos()\n",
    "    videos = torch.stack(list_videos, dim = 0)\n",
    "    torch.save(videos, f'./TGIF/videos_{i}.pt')\n",
    "    with open(f'./TGIF/texts_{i}.txt', 'w') as fp:\n",
    "        fp.write('\\n'.join(texts))\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
