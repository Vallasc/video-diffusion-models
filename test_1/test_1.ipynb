{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2123baae",
   "metadata": {},
   "source": [
    "# Video diffusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447b882b-5aff-47ac-a1da-6b7a0f76e04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test 1\n",
    "image_size = 128\n",
    "frames = 10\n",
    "max_images = 125782\n",
    "download_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f2ab4a9-bf1b-464a-b79b-a232269649a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Collecting torch==1.12.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torch-1.12.1%2Bcu116-cp39-cp39-linux_x86_64.whl (1904.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 GB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hCollecting torchvision==0.13.1+cu116\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchvision-0.13.1%2Bcu116-cp39-cp39-linux_x86_64.whl (23.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio==0.12.1\n",
      "  Downloading https://download.pytorch.org/whl/cu116/torchaudio-0.12.1%2Bcu116-cp39-cp39-linux_x86_64.whl (3.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.12.1+cu116) (4.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu116) (2.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu116) (1.23.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.13.1+cu116) (9.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu116) (1.26.10)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision==0.13.1+cu116) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision==0.13.1+cu116) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision==0.13.1+cu116) (2019.11.28)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.12.0+cu116\n",
      "    Uninstalling torch-1.12.0+cu116:\n",
      "      Successfully uninstalled torch-1.12.0+cu116\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.13.0+cu116\n",
      "    Uninstalling torchvision-0.13.0+cu116:\n",
      "      Successfully uninstalled torchvision-0.13.0+cu116\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.12.0+cu116\n",
      "    Uninstalling torchaudio-0.12.0+cu116:\n",
      "      Successfully uninstalled torchaudio-0.12.0+cu116\n",
      "Successfully installed torch-1.12.1+cu116 torchaudio-0.12.1+cu116 torchvision-0.13.1+cu116\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting imagen_pytorch==1.16.5\n",
      "  Downloading imagen_pytorch-1.16.5-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beartype\n",
      "  Downloading beartype-0.11.0-py3-none-any.whl (702 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m702.5/702.5 kB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (8.1.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (1.23.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (2.3.2)\n",
      "Collecting ema-pytorch>=0.0.3\n",
      "  Downloading ema_pytorch-0.1.2-py3-none-any.whl (4.2 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (4.64.0)\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.8.4.post0-py3-none-any.whl (800 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.3/800.3 kB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6 in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (1.12.1+cu116)\n",
      "Collecting pytorch-warmup\n",
      "  Downloading pytorch_warmup-0.1.1-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (4.20.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (0.1.96)\n",
      "Collecting kornia\n",
      "  Downloading kornia-0.6.8-py2.py3-none-any.whl (551 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m551.1/551.1 kB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting einops>=0.6\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (0.13.1+cu116)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (21.3)\n",
      "Collecting einops-exts\n",
      "  Downloading einops_exts-0.0.3-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (1.9.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.5/191.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (2022.5.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from imagen_pytorch==1.16.5) (9.2.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.6->imagen_pytorch==1.16.5) (4.3.0)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from accelerate->imagen_pytorch==1.16.5) (5.4.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from accelerate->imagen_pytorch==1.16.5) (5.9.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->imagen_pytorch==1.16.5) (3.0.9)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (8.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (0.8.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (1.4.3)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (0.18.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (3.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (3.8.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (0.70.13)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->imagen_pytorch==1.16.5) (2.28.1)\n",
      "Collecting tensorboardX>=2.2\n",
      "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting lightning-utilities!=0.4.0,>=0.3.0\n",
      "  Downloading lightning_utilities-0.4.2-py3-none-any.whl (16 kB)\n",
      "Collecting torchmetrics>=0.7.0\n",
      "  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.4/512.4 kB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->imagen_pytorch==1.16.5) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->imagen_pytorch==1.16.5) (3.7.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->imagen_pytorch==1.16.5) (2022.7.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->imagen_pytorch==1.16.5) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->imagen_pytorch==1.16.5) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->imagen_pytorch==1.16.5) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->imagen_pytorch==1.16.5) (2.8)\n",
      "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorboardX>=2.2->pytorch-lightning->imagen_pytorch==1.16.5) (3.19.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->imagen_pytorch==1.16.5) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->imagen_pytorch==1.16.5) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->imagen_pytorch==1.16.5) (18.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->imagen_pytorch==1.16.5) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->imagen_pytorch==1.16.5) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->imagen_pytorch==1.16.5) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->imagen_pytorch==1.16.5) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets->imagen_pytorch==1.16.5) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->imagen_pytorch==1.16.5) (1.14.0)\n",
      "Installing collected packages: tensorboardX, lightning-utilities, einops, beartype, torchmetrics, pytorch-warmup, kornia, ema-pytorch, einops-exts, accelerate, pytorch-lightning, imagen_pytorch\n",
      "Successfully installed accelerate-0.15.0 beartype-0.11.0 einops-0.6.0 einops-exts-0.0.3 ema-pytorch-0.1.2 imagen_pytorch-1.16.5 kornia-0.6.8 lightning-utilities-0.4.2 pytorch-lightning-1.8.4.post0 pytorch-warmup-0.1.1 tensorboardX-2.5.1 torchmetrics-0.11.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install imagen dependencies\n",
    "!pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "!pip install imagen_pytorch==1.16.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "882c2eb2-e24e-41d7-9087-2f34941e54b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GIF pre-processing\n",
    "\n",
    "import numpy as np\n",
    "from torchvision import transforms as T\n",
    "from math import floor, fabs\n",
    "from PIL import Image, ImageSequence\n",
    "\n",
    "\n",
    "CHANNELS_TO_MODE = {\n",
    "    1 : 'L',\n",
    "    3 : 'RGB',\n",
    "    4 : 'RGBA'\n",
    "}\n",
    "\n",
    "def center_crop(img, new_width, new_height): \n",
    "    width = img.size[0]\n",
    "    height = img.size[1]\n",
    "    left = int(np.ceil((width - new_width) / 2))\n",
    "    right = width - int(np.floor((width - new_width) / 2))\n",
    "    top = int(np.ceil((height - new_height) / 2))\n",
    "    bottom = height - int(np.floor((height - new_height) / 2))\n",
    "    return img.crop((left, top, right, bottom))\n",
    "\n",
    "def resize_crop_img(img, width, height):\n",
    "    # width < height\n",
    "    if( img.size[0] < img.size[1]):\n",
    "      wpercent = (width/float(img.size[0]))\n",
    "      hsize = int((float(img.size[1])*float(wpercent)))\n",
    "      img = img.resize((width, hsize), Image.Resampling.LANCZOS)\n",
    "    else: # width >= height\n",
    "      hpercent = (height/float(img.size[1]))\n",
    "      wsize = int((float(img.size[0])*float(hpercent)))\n",
    "      img = img.resize((wsize, height), Image.Resampling.LANCZOS)\n",
    "    img = center_crop(img, width, height)\n",
    "    # print(img.size[0])\n",
    "    # print(img.size[1])\n",
    "    return img\n",
    "\n",
    "def transform_gif(img, new_width, new_height, frames, channels = 3):\n",
    "    assert channels in CHANNELS_TO_MODE, f'channels {channels} invalid'\n",
    "    mode = CHANNELS_TO_MODE[channels]\n",
    "    gif_frames = img.n_frames\n",
    "    for i in range(0, frames):\n",
    "        img.seek(i % gif_frames)\n",
    "        img_out = resize_crop_img(img, new_width, new_height)\n",
    "        yield img_out.convert(mode)\n",
    "        \n",
    "# tensor of shape (channels, frames, height, width) -> gif\n",
    "def video_tensor_to_gif(tensor, path, fps = 10, loop = 0, optimize = True):\n",
    "    print(\"Converting video tensors to GIF\")\n",
    "    images = map(T.ToPILImage(), tensor.unbind(dim = 1))\n",
    "    first_img, *rest_imgs = images\n",
    "    print(1000/fps)\n",
    "    first_img.save(path, save_all = True, append_images = rest_imgs, duration = int(1000/fps), loop = loop, optimize = optimize)\n",
    "    print(\"Gif saved\")\n",
    "    return images\n",
    "\n",
    "# gif -> (channels, frame, height, width) tensor\n",
    "def gif_to_tensor(path, width = 256, height = 256, frames = 32, channels = 3, transform = T.ToTensor()):\n",
    "    print(\"Converting GIF to video tensors\")\n",
    "    img = Image.open(path)\n",
    "    imgs = transform_gif(img, new_width = width, new_height = height, frames = frames, channels = channels)\n",
    "    tensors = tuple(map(transform, imgs))\n",
    "    return torch.stack(tensors, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fda94dd-6120-4ddc-8632-1cff5eb27e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "train_data = \"./train_data.tvs\"\n",
    "train_index = \"./train_index.txt\"\n",
    "\n",
    "if not os.path.exists(train_data):\n",
    "  !wget -O {train_data} https://raw.githubusercontent.com/raingo/TGIF-Release/master/data/tgif-v1.0.tsv\n",
    "\n",
    "current_index = 0\n",
    "texts = []\n",
    "list_videos = []\n",
    "\n",
    "def get_videos(index_start, index_end):\n",
    "    global texts\n",
    "    global list_videos\n",
    "    \n",
    "    texts = []\n",
    "    list_videos = []\n",
    "    max_iter = 100\n",
    "\n",
    "    with open(\"train_data.tvs\") as fp:\n",
    "        for i, line in enumerate(fp):\n",
    "            if i >= index_start and i< index_end :\n",
    "                file_img, file_text = line.split(\"\\t\")\n",
    "                try:\n",
    "                    print(f\"Downloading image {i}\")\n",
    "                    !wget -O download.gif -o /dev/null {file_img}\n",
    "                    tensor = gif_to_tensor('download.gif', width = image_size, height = image_size, frames = frames)\n",
    "                    list_videos.append(tensor)\n",
    "                    file_text = file_text[:-1] # Remove \\n\n",
    "                    texts.append(file_text)\n",
    "                    os.remove('download.gif')\n",
    "                except Exception as ex:\n",
    "                    print(ex)\n",
    "                    pass\n",
    "            elif i > index_end:\n",
    "                break\n",
    "\n",
    "def get_next_videos():\n",
    "    global current_index\n",
    "    index = 0\n",
    "    if not os.path.exists(train_index):\n",
    "        with open(train_index, 'w') as fp:\n",
    "            fp.write(\"0\")\n",
    "    else:\n",
    "        with open(train_index, 'r') as fp:\n",
    "            index = int(fp.readlines()[0])\n",
    "    index_end = index + download_batch_size\n",
    "    get_videos(index, index_end)\n",
    "    with open(train_index, 'w') as fp:\n",
    "        fp.write(f\"{index_end}\")\n",
    "    current_index = index_end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4dfc722-70d4-4f47-a0bd-275242c33d92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d6c269e2c54e0ca2a7018d042a8a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/beartype/_util/hint/pep/utilpeptest.py:345: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.List[str] deprecated by PEP 585 scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". See this discussion for further details and alternatives:\n",
      "    https://github.com/beartype/beartype#pep-585-deprecations\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import torch\n",
    "import datetime\n",
    "import gc\n",
    "from imagen_pytorch import Unet3D, ElucidatedImagen, ImagenTrainer\n",
    "from imagen_pytorch.data import Dataset\n",
    "\n",
    "checkpoints_path = \"./\"\n",
    "last_checkpoint_path = os.path.join(checkpoints_path, \"last_checkpoint.txt\")\n",
    "\n",
    "def save_checkpoint(trainer: ImagenTrainer, unet, step):\n",
    "    print(\"Saving checkpoint\")\n",
    "    current_datetime = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    new_checkpoint_path = os.path.join(checkpoints_path, f\"checkpoint-unet{unet}-step{step}-{current_datetime}.pt\")\n",
    "    trainer.save(new_checkpoint_path)\n",
    "    if os.path.exists(last_checkpoint_path):\n",
    "        with open(last_checkpoint_path, 'r') as fp:\n",
    "            os.remove(fp.readlines()[0])\n",
    "    with open(last_checkpoint_path, 'w') as fp:\n",
    "        fp.write(new_checkpoint_path)\n",
    "\n",
    "def load_checkpoint(trainer: ImagenTrainer):\n",
    "    if not os.path.exists(last_checkpoint_path):\n",
    "        return None\n",
    "    with open(last_checkpoint_path, 'r') as fp:\n",
    "        checkpoint_path = fp.readlines()[0]\n",
    "        try:\n",
    "            print(\"Loading checkpoint\")\n",
    "            trainer.load(checkpoint_path)\n",
    "        except:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1846fbf4-7bec-40d2-8fd4-ee0ef41f9332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/\n"
     ]
    }
   ],
   "source": [
    "unet1 = Unet3D(\n",
    "    dim = 64,\n",
    "    cond_dim = 128,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "unet2 = Unet3D(\n",
    "    dim = 64,\n",
    "    cond_dim = 128,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "imagen = ElucidatedImagen(\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (16, 64),\n",
    "    random_crop_sizes = (None, 16),\n",
    "    num_sample_steps = 10,\n",
    "    # timesteps = 1000,\n",
    "    cond_drop_prob = 0.1,                       # gives the probability of dropout for classifier-free guidance.\n",
    "    sigma_min = 0.002,                          # min noise level\n",
    "    sigma_max = (80, 160),                      # max noise level, double the max noise level for upsampler\n",
    "    sigma_data = 0.5,                           # standard deviation of data distribution\n",
    "    rho = 7,                                    # controls the sampling schedule\n",
    "    P_mean = -1.2,                              # mean of log-normal distribution from which noise is drawn for training\n",
    "    P_std = 1.2,                                # standard deviation of log-normal distribution from which noise is drawn for training\n",
    "    S_churn = 80,                               # parameters for stochastic sampling - depends on dataset, Table 5 in apper\n",
    "    S_tmin = 0.05,\n",
    "    S_tmax = 50,\n",
    "    S_noise = 1.003,\n",
    ").cuda()\n",
    "\n",
    "trainer = ImagenTrainer(imagen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df922ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint\n",
      "Downloading image 5376\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5377\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5378\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5379\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5380\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5381\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5382\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5383\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5384\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5385\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5386\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5387\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5388\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5389\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5390\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5391\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5392\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5393\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5394\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5395\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5396\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5397\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5398\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5399\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5400\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5401\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5402\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5403\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5404\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5405\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5406\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5407\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5408\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5409\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5410\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5411\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5412\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5413\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5414\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5415\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5416\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5417\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5418\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5419\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5420\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5421\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5422\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5423\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5424\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5425\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5426\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5427\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5428\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5429\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5430\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5431\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5432\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5433\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5434\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5435\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5436\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5437\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5438\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5439\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5440\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5441\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5442\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5443\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5444\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5445\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5446\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5447\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5448\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5449\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5450\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5451\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5452\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5453\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5454\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5455\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5456\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5457\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5458\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5459\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5460\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5461\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5462\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5463\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5464\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5465\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5466\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5467\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5468\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5469\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5470\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5471\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5472\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5473\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5474\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5475\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5476\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5477\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5478\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5479\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5480\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5481\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5482\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5483\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5484\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5485\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5486\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5487\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5488\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5489\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5490\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5491\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5492\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5493\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5494\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5495\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5496\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5497\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5498\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5499\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5500\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5501\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5502\n",
      "Converting GIF to video tensors\n",
      "Downloading image 5503\n",
      "Converting GIF to video tensors\n",
      "Generating tensor from videos\n",
      "Training unet-1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528dc19b42354aea970a9c163de40b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/945M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29528c96df4b4ec582d1248a66aca2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0059f438afef4fe392efdcf989241326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d14226dd08b41c7adb29663febc08b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory\n",
      "1850773504\n",
      "Saving checkpoint\n",
      "checkpoint saved to ./checkpoint-unet1-step5504-20221212-103737.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './checkpoints/checkpoint-unet1-step5376-20221212-032038.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllocated memory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mmemory_allocated())\n\u001b[0;32m---> 18\u001b[0m \u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36msave_checkpoint\u001b[0;34m(trainer, unet, step)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(last_checkpoint_path):\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(last_checkpoint_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m---> 18\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(last_checkpoint_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[1;32m     20\u001b[0m     fp\u001b[38;5;241m.\u001b[39mwrite(new_checkpoint_path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/checkpoint-unet1-step5376-20221212-032038.pt'"
     ]
    }
   ],
   "source": [
    "# Train Unet 1\n",
    "unet = 1\n",
    "load_checkpoint(trainer)\n",
    "\n",
    "while True:\n",
    "    get_next_videos()\n",
    "    if len(texts) == 0:\n",
    "        break\n",
    "    print(\"Generating tensor from videos\")\n",
    "    videos = torch.stack(list_videos, dim = 0).cuda()\n",
    "    print(f\"Training unet-{unet}\")\n",
    "    trainer(videos, texts = texts, unet_number = unet, max_batch_size = 32)\n",
    "    trainer.update(unet_number = unet)\n",
    "    del videos\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Allocated memory\")\n",
    "    print(torch.cuda.memory_allocated())\n",
    "    save_checkpoint(trainer, unet, current_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91dc254d-5a7b-4672-bf92-e685af1a7960",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-06T10:10:55.723283Z",
     "iopub.status.busy": "2022-12-06T10:10:55.722943Z",
     "iopub.status.idle": "2022-12-06T10:12:06.166695Z",
     "shell.execute_reply": "2022-12-06T10:12:06.165700Z",
     "shell.execute_reply.started": "2022-12-06T10:10:55.723245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base dimension of your u-net should ideally be no smaller than 128, as recommended by a professional DDPM trainer https://nonint.com/2022/05/04/friends-dont-let-friends-train-small-diffusion-models/\n",
      "Loading checkpoint\n",
      "checkpoint loaded from ./checkpoints/checkpoint-unet1-step128-20221211-185101.pt\n",
      "Downloading image 128\n",
      "Converting GIF to video tensors\n",
      "Downloading image 129\n",
      "Converting GIF to video tensors\n",
      "Downloading image 130\n",
      "Converting GIF to video tensors\n",
      "Downloading image 131\n",
      "Converting GIF to video tensors\n",
      "Downloading image 132\n",
      "Converting GIF to video tensors\n",
      "Downloading image 133\n",
      "Converting GIF to video tensors\n",
      "Downloading image 134\n",
      "Converting GIF to video tensors\n",
      "Downloading image 135\n",
      "Converting GIF to video tensors\n",
      "Downloading image 136\n",
      "Converting GIF to video tensors\n",
      "Downloading image 137\n",
      "Converting GIF to video tensors\n",
      "Downloading image 138\n",
      "Converting GIF to video tensors\n",
      "Downloading image 139\n",
      "Converting GIF to video tensors\n",
      "Downloading image 140\n",
      "Converting GIF to video tensors\n",
      "Downloading image 141\n",
      "Converting GIF to video tensors\n",
      "Downloading image 142\n",
      "Converting GIF to video tensors\n",
      "Downloading image 143\n",
      "Converting GIF to video tensors\n",
      "Downloading image 144\n",
      "Converting GIF to video tensors\n",
      "Downloading image 145\n",
      "Converting GIF to video tensors\n",
      "Downloading image 146\n",
      "Converting GIF to video tensors\n",
      "Downloading image 147\n",
      "Converting GIF to video tensors\n",
      "Downloading image 148\n",
      "Converting GIF to video tensors\n",
      "Downloading image 149\n",
      "Converting GIF to video tensors\n",
      "Downloading image 150\n",
      "Converting GIF to video tensors\n",
      "Downloading image 151\n",
      "Converting GIF to video tensors\n",
      "Downloading image 152\n",
      "Converting GIF to video tensors\n",
      "Downloading image 153\n",
      "Converting GIF to video tensors\n",
      "Downloading image 154\n",
      "Converting GIF to video tensors\n",
      "Downloading image 155\n",
      "Converting GIF to video tensors\n",
      "Downloading image 156\n",
      "Converting GIF to video tensors\n",
      "Downloading image 157\n",
      "Converting GIF to video tensors\n",
      "Downloading image 158\n",
      "Converting GIF to video tensors\n",
      "Downloading image 159\n",
      "Converting GIF to video tensors\n",
      "Downloading image 160\n",
      "Converting GIF to video tensors\n",
      "Downloading image 161\n",
      "Converting GIF to video tensors\n",
      "Downloading image 162\n",
      "Converting GIF to video tensors\n",
      "Downloading image 163\n",
      "Converting GIF to video tensors\n",
      "Downloading image 164\n",
      "Converting GIF to video tensors\n",
      "Downloading image 165\n",
      "Converting GIF to video tensors\n",
      "Downloading image 166\n",
      "Converting GIF to video tensors\n",
      "Downloading image 167\n",
      "Converting GIF to video tensors\n",
      "Downloading image 168\n",
      "Converting GIF to video tensors\n",
      "Downloading image 169\n",
      "Converting GIF to video tensors\n",
      "Downloading image 170\n",
      "Converting GIF to video tensors\n",
      "Downloading image 171\n",
      "Converting GIF to video tensors\n",
      "Downloading image 172\n",
      "Converting GIF to video tensors\n",
      "Downloading image 173\n",
      "Converting GIF to video tensors\n",
      "Downloading image 174\n",
      "Converting GIF to video tensors\n",
      "Downloading image 175\n",
      "Converting GIF to video tensors\n",
      "Downloading image 176\n",
      "Converting GIF to video tensors\n",
      "Downloading image 177\n",
      "Converting GIF to video tensors\n",
      "Downloading image 178\n",
      "Converting GIF to video tensors\n",
      "Downloading image 179\n",
      "Converting GIF to video tensors\n",
      "Downloading image 180\n",
      "Converting GIF to video tensors\n",
      "Downloading image 181\n",
      "Converting GIF to video tensors\n",
      "Downloading image 182\n",
      "Converting GIF to video tensors\n",
      "Downloading image 183\n",
      "Converting GIF to video tensors\n",
      "Downloading image 184\n",
      "Converting GIF to video tensors\n",
      "Downloading image 185\n",
      "Converting GIF to video tensors\n",
      "Downloading image 186\n",
      "Converting GIF to video tensors\n",
      "Downloading image 187\n",
      "Converting GIF to video tensors\n",
      "Downloading image 188\n",
      "Converting GIF to video tensors\n",
      "Downloading image 189\n",
      "Converting GIF to video tensors\n",
      "Downloading image 190\n",
      "Converting GIF to video tensors\n",
      "Downloading image 191\n",
      "Converting GIF to video tensors\n",
      "Generating tensor from videos\n",
      "Training unet-2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5144103b2d45b585be5b0feca86f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/945M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bba2470910744cfa6272b8d1f5c5d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/773k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a70a6f813384c90801b651414824c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7907ac3d272a42e2a0bdca2ae055c374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated memory\n",
      "3529052672\n",
      "Saving checkpoint\n",
      "checkpoint saved to ./checkpoints/checkpoint-unet2-step192-20221211-190038.pt\n"
     ]
    }
   ],
   "source": [
    "# # Train Unet 2\n",
    "# unet = 2\n",
    "# load_checkpoint(trainer)\n",
    "\n",
    "# while True:\n",
    "#     get_next_videos()\n",
    "#     if len(texts) == 0:\n",
    "#         break\n",
    "#     print(\"Generating tensor from videos\")\n",
    "#     videos = torch.stack(list_videos, dim = 0).cuda()\n",
    "#     print(f\"Training unet-{unet}\")\n",
    "#     trainer(videos, texts = texts, unet_number = unet, max_batch_size = 32)\n",
    "#     trainer.update(unet_number = unet)\n",
    "#     del videos\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print(\"Allocated memory\")\n",
    "#     print(torch.cuda.memory_allocated())\n",
    "#     save_checkpoint(trainer, unet, current_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d81e6fc-ff11-47d1-9c07-2cc3044cf438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GPUtil\n",
      "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: GPUtil\n",
      "  Building wheel for GPUtil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7394 sha256=9e59b4827870b979608e22fafd27d86dddbe0e49710f6ae3fa0fc74616de8e71\n",
      "  Stored in directory: /root/.cache/pip/wheels/2b/b5/24/fbb56595c286984f7315ee31821d6121e1b9828436021a88b3\n",
      "Successfully built GPUtil\n",
      "Installing collected packages: GPUtil\n",
      "Successfully installed GPUtil-1.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% | 98% |\n"
     ]
    }
   ],
   "source": [
    "# !pip install GPUtil\n",
    "\n",
    "# from GPUtil import showUtilization as gpu_usage\n",
    "# gpu_usage()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f54486-5fb4-4670-aa5b-a02837145fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "82870c2f554ac463822076b994cf0f6148cb66eef85ce34abb8e9fcae1bddbbc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
